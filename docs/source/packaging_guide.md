
# Pip Package Guide


## Code Structure 

This guide describes the updates to bark probject as part of pip packaging work and builds upon bark with updated directory structure for concise import paths, along with other changes and updates required for the packaging process.  

All the modules  are now sub-module of main bark module, and are imported w.r.t it.  C++ python bindings previously in python folder are now in python_wrapper folder under bark main directory and similarly components from module directory are also placed directly under bark directory. C++ python library is renamed `core.so` from `bark.so` and all modules imported from the C++ library are under bark.core.*.

> The import paths have been updated from following

`from modules.runtime.commons.parameters import ParameterServer`   
`from bark.world import World`   

> to a more concise format as

`from bark.runtime.commons import ParameterServer`   
`from bark.core.world import World`   

## Build Package source
To have all the modules, together in a single library, a `py_binary` target  `//bark:pip_package`is created with all the `py_library`'s as its dependencies. Upon successful build of this target, all the modules are found under **bark_project** (workspace name) in the  pip_package.runfiles directory in the out folder, together with their dependencies in the external folder. The content under this bark_project directory is later combined into a wheel package.

### PATH Update
As Bazel automatically handles managing paths for dependencies when running a target, for a pip package it has to be performed manually and is done in `__init__.py` file in the main bark directory. Here we update the path with  all the external projects and packages that are required in bark code.

### Build Tests
Similar to Bazel testing `bazel test //...` , it has to be ensured that, all tests execute during packaging, albeit under a different environment without Bazel.
To ensure all the tests are also included in the generated out folder, a new Bazel test target is created with all the tests as its dependencies and this target is added as dependency to the `//bark:pip_package` target which causes the tests to be placed in the out directory following the same relative path structure as for other code. 
 > Note: Test execution is discussed under Packaging.

#### Data Paths
Tests implemented for the modules and sub-modules(as Bazel py_test targets) import required data w.r.t main Bazel WORKSPACE path not w.r.t that respective module, and as Bazel manages the paths for targets it runs so it does not pose an issue as it runs all code from main bazel out directory. In a pip package, the paths are different depending upon where the packages are installed and from where the user is executing the code, therefore the code has to be updated to import required data files by combining the absolute path of the package directory(not the user current path) with the relative target w.r.t the package. 
> For example to load a data, previously it was implemented as

`xodr_parser = XodrParser("bark/runtime/tests/data/Crossing8Course.xodr")` 
> Now, we need to specify the path relative wrt the respective module.

`xodr_parser =  XodrParser(os.path.join(os.path.dirname(__file__),"data/Crossing8Course.xodr"))`

> **Note:** The  change does not affect the  **bazel tests** as using absolute path instead of relative results in same path anyways.


## Packaging
After successful build of `//bark:pip_package` , the packaging process takes place under the generated respective runfiles directory as mentioned earlier.  
A provided bash script `package.sh` manages the complete process from code compiling and pip package generation to uploading to PyPi. The process shall be discussed after a brief introduction of the components required to generate the package.

This script **`setup.py`** identifies a python code directory along with sub directories containing `__init__.py` as a potential pip package and provides interface upon which the pip package is built and includes details about basic package information like description, version and dependencies etc.

### Automating Script
A script  `package.sh` is provided which handles the complete pipeline for package generation & distribution as a python library. This script performs the following tasks:
- Compile Bazel target representing the pip package `//bark:pip_package`
- Copy `setup.py`, `LICENSE`, `readme.md` to the target location in the package.runfiles generated directory so they can be added to the wheel package.
- Generate **`MANIFEST.in`** 
	- This file includes the list of all the required data files that have to be added to the package but are not a standard python script so they have to be manually identified
	- To generate this file, we make use of a file called **MANIFEST** that is auto generated by bazel for the respective target and is present in the aforementioned out generated directory. 

### Run tests
- Building pip_package also builds all tests and as like other targets, tests are copied in the respective folders in the out path
- The **`setup.py`** makes use of test suite `nose.collector` to identify all the unitest's in the code directory.
- `python3 setup.py test` executes the tests.
- If any test fail the script stops and exits with an Error message.
#### Build and distribute
After successful completion of tests, the package is built using 
- `python3 setup.py sdist bdist_wheel`
> Note: The above command automatically identifies if the code is pure python package, in which case the package is available for all platforms and configurations. In our case we make use of locally compiled thus platform dependent`core.so` shared library(exposing  C++  functionality of Bark API) . 
> But as the Library is not compiled using `setup.py` script so the script does not identify the shared library and considers the package as a standard python package. Adding an extra empty extension under `ext_modules` instructs the package building code to mark the wheel file as a platform dependent code, thus generating a wheel file for the specific build platform.
> Therefore, when installing the package using `pip install ..`  the pip will pick the appropriate wheel to install. 
> This approach works for non Linux distributions only as setup.py generates literal platform specific versions  for non Linux OS's while for all the Linux distros it generates a generic linux_x86_64 tag, which is rejected by PyPi repository.  For Linux, the [PyPi standard](https://packaging.python.org/specifications/platform-compatibility-tags/) requires that a standard docker image called [manylinux](https://github.com/pypa/manylinux) be used for building the wheel. 
> The process for building pip package in the specified docker container has some complications caused by Bazel support along with C++ libraries. so the  current approach is to have version specific wheels for Mac OS and a generic wheel for Linux based systems that is build on Ubuntu 64. It shall not work with all of Linux distros but shall be compatible with most of debian based architectures.
 
Once a wheel is built, it can be uploaded to PyPi repository `python3 -m twine upload --skip-existing dist/*`

